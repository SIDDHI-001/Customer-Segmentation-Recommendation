# -*- coding: utf-8 -*-
"""Custumer Segmentation .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t3IaaPyy2yWOnJ29mS2bGHyGkzD1Evw1

# **Custumer Segmentation And AI Recomendation**
"""

#Name : Deore Siddhi Arun
#Internship : AI Intern

!pip install pandas numpy scikit-learn matplotlib seaborn plotly --quiet

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sn s
import plotly.express as px
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score
from sklearn.neighbors import NearestNeighbors
import zipfile, os

# In Colab, run this and upload:
# - events.csv.zip
# - item_properties_part1.zip
# - item_properties_part2.zip
# - category_tree.csv

from google.colab import files
uploaded = files.upload()

from google.colab import files

# This will prompt you to upload both zip files
uploaded = files.upload()

import zipfile
import os

# Optional: check files in current directory
print("Uploaded files:", os.listdir())

# Unzip events
with zipfile.ZipFile("events.csv.zip", "r") as z:
    z.extractall("events")  # Extract into 'events' folder

# Unzip item_properties parts using exact names
with zipfile.ZipFile("item_properties_part1.csv (1).zip", "r") as z:
    z.extractall("item_properties_part1")  # Extract into folder

with zipfile.ZipFile("item_properties_part2.csv (1).zip", "r") as z:
    z.extractall("item_properties_part2")  # Extract into folder

# Check extracted folders
print("Events files:", os.listdir("events"))
print("Item Properties Part 1 files:", os.listdir("item_properties_part1"))
print("Item Properties Part 2 files:", os.listdir("item_properties_part2"))

# Load item_properties CSVs from their folders
item1 = pd.read_csv("item_properties_part1/item_properties_part1.csv")
item2 = pd.read_csv("item_properties_part2/item_properties_part2.csv")

# Combine both parts
item_properties = pd.concat([item1, item2], ignore_index=True)

# Save the merged CSV
item_properties.to_csv("item_properties.csv", index=False)

# Optional: preview first few rows
print(item_properties.head())

events = pd.read_csv("events.csv")
item_properties = pd.read_csv("item_properties.csv")
category_tree = pd.read_csv("category_tree.csv")

print("Events shape:", events.shape)
print("Item properties shape:", item_properties.shape)
print("Category tree shape:", category_tree.shape)

# Filter only purchase (transaction) events
transactions = events[events['event'] == 'transaction']

# Merge with category info
item_props_filtered = item_properties[item_properties['property'] == 'categoryid']
transactions = transactions.merge(item_props_filtered, on="itemid", how="left")

# Clean missing values
transactions = transactions.dropna()
transactions.head()

customer_features = transactions.groupby("visitorid").agg({
    "itemid": "count",
    "transactionid": "nunique",
}).reset_index()

customer_features.rename(
    columns={"itemid": "total_items", "transactionid": "unique_transactions"},
    inplace=True
)

customer_features.head()

scaler = StandardScaler()
X_scaled = scaler.fit_transform(customer_features[["total_items", "unique_transactions"]])

kmeans = KMeans(n_clusters=3, random_state=42)
customer_features['cluster'] = kmeans.fit_predict(X_scaled)

print("Silhouette Score (KMeans):", silhouette_score(X_scaled, customer_features['cluster']))

dbscan = DBSCAN(eps=0.5, min_samples=5)
customer_features['dbscan_cluster'] = dbscan.fit_predict(X_scaled)

fig = px.scatter(
    customer_features,
    x="total_items",
    y="unique_transactions",
    color="cluster",
    title="Customer Segments (KMeans)",
    template="plotly_dark"
)
fig.show()

fig = px.scatter(
    customer_features,
    x="total_items",
    y="unique_transactions",
    color="cluster",
    title="Customer Segments (KMeans)",
    template="plotly_dark"
)
fig.show()

basket = transactions.groupby(['visitorid', 'itemid']).size().unstack(fill_value=0)

model_knn = NearestNeighbors(metric='cosine', algorithm='brute')
model_knn.fit(basket.values)

visitor_id = customer_features['visitorid'].iloc[0]
visitor_vector = basket.loc[visitor_id].values.reshape(1, -1)

distances, indices = model_knn.kneighbors(visitor_vector, n_neighbors=5)
print(f"Recommendations for visitor {visitor_id}:")
print(basket.index[indices.flatten()].tolist())

print("\nCluster Insights:")
for c in customer_features['cluster'].unique():
    group = customer_features[customer_features['cluster'] == c]
    print(f"Cluster {c}: Avg Items = {group['total_items'].mean():.2f}, Avg Transactions = {group['unique_transactions'].mean():.2f}")